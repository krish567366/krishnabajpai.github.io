import React from 'react';
import Layout from "@/components/layout/Layout";
import { Helmet } from "react-helmet";
import { Link } from "react-router-dom";

const ComputerVisionQualityControl = () => {
  return (
    <>
      <Helmet>
        <title>How I Built an AI Quality Control System That Reduced Manufacturing Defects by 67% | Krishna Bajpai</title>
        <meta name="description" content="Computer vision quality control achieved 99.7% accuracy in automotive manufacturing using YOLO defect detection. Edge deployment & production pipeline. Complete guide." />
        <meta name="keywords" content="computer vision, quality control, manufacturing AI, defect detection, YOLO, edge computing, Krishna Bajpai" />
        <link rel="canonical" href="https://krishnabajpai.me/blog/computer-vision-quality-control" />
        <meta property="og:title" content="AI Quality Control System That Reduced Manufacturing Defects by 67%" />
        <meta property="og:description" content="Computer vision defect detection system with 99.7% accuracy in automotive manufacturing" />
        <meta property="og:url" content="https://krishnabajpai.me/blog/computer-vision-quality-control" />
        <meta property="og:type" content="article" />
        <script type="application/ld+json">{`
          {
            "@context": "https://schema.org",
            "@type": "BlogPosting",
            "headline": "How I Built an AI Quality Control System That Reduced Manufacturing Defects by 67%",
            "description": "Real-world case study of implementing computer vision-powered quality control for automotive manufacturing. YOLO-based defect detection, edge deployment, and 99.7% accuracy achievement.",
            "image": "https://krishnabajpai.me/assets/hero-flow.png",
            "author": {
              "@type": "Person",
              "name": "Krishna Bajpai",
              "url": "https://krishnabajpai.me",
              "sameAs": [
                "https://www.linkedin.com/in/krishnabajpai/",
                "https://github.com/krishnabajpai"
              ]
            },
            "publisher": {
              "@type": "Person",
              "name": "Krishna Bajpai",
              "url": "https://krishnabajpai.me"
            },
            "datePublished": "2025-11-19T08:00:00Z",
            "dateModified": "2025-11-19T12:00:00Z",
            "url": "https://krishnabajpai.me/blog/computer-vision-quality-control",
            "mainEntityOfPage": {
              "@type": "WebPage",
              "@id": "https://krishnabajpai.me/blog/computer-vision-quality-control"
            },
            "articleSection": "Computer Vision",
            "wordCount": 3800,
            "timeRequired": "PT11M",
            "keywords": ["computer vision", "quality control", "manufacturing AI", "defect detection", "YOLO", "edge computing"],
            "about": [
              {
                "@type": "Thing",
                "name": "Computer Vision"
              },
              {
                "@type": "Thing", 
                "name": "Quality Control"
              },
              {
                "@type": "Thing",
                "name": "Manufacturing AI"
              }
            ],
            "inLanguage": "en-US"
          }
        `}</script>
        <script type="application/ld+json">{`
          {
            "@context": "https://schema.org",
            "@type": "BreadcrumbList",
            "itemListElement": [
              {
                "@type": "ListItem",
                "position": 1,
                "name": "Home",
                "item": "https://krishnabajpai.me"
              },
              {
                "@type": "ListItem",
                "position": 2,
                "name": "Blog",
                "item": "https://krishnabajpai.me/blog"
              },
              {
                "@type": "ListItem",
                "position": 3,
                "name": "AI Quality Control System for Manufacturing",
                "item": "https://krishnabajpai.me/blog/computer-vision-quality-control"
              }
            ]
          }
        `}</script>
      </Helmet>
      
      <Layout>
        <div className="py-20">
          <div className="container mx-auto px-6 lg:px-8">
            <div className="max-w-4xl mx-auto">
              {/* Breadcrumb */}
              <nav className="mb-8">
                <Link to="/blog" className="text-accent hover:text-foreground">
                  ‚Üê Back to Blog
                </Link>
              </nav>

              {/* Article Header */}
              <header className="mb-12">
                <div className="mb-4">
                  <span className="px-3 py-1 bg-accent/10 text-accent rounded-full text-sm">
                    Computer Vision
                  </span>
                </div>
                <h1 className="text-4xl font-light text-foreground mb-6 leading-tight">
                  How I Built an AI Quality Control System That Reduced Manufacturing Defects by 67%
                </h1>
                <div className="flex items-center text-muted-foreground text-sm space-x-4">
                  <span>November 19, 2025</span>
                  <span>‚Ä¢</span>
                  <span>11 min read</span>
                  <span>‚Ä¢</span>
                  <span>Krishna Bajpai</span>
                </div>
              </header>

              {/* Article Content */}
              <article className="prose prose-lg max-w-none text-foreground">
                <p className="text-xl leading-relaxed text-muted-foreground mb-8">
                  When an automotive parts manufacturer was losing $1.2M annually due to defective products reaching 
                  customers, traditional quality control wasn't cutting it. Here's how I built a computer vision system 
                  that achieved 99.7% defect detection accuracy and reduced manufacturing defects by 67%.
                </p>

                <h2 className="text-2xl font-medium text-foreground mt-12 mb-6">The Challenge: Manual Inspection Bottleneck</h2>
                <p className="mb-6">
                  The client manufactured precision automotive components with zero-defect tolerance, but their quality control process had serious limitations:
                </p>
                
                <div className="bg-secondary p-6 rounded-lg mb-8">
                  <h3 className="text-lg font-medium text-foreground mb-4">Pre-AI Quality Control Issues</h3>
                  <ul className="space-y-2 text-muted-foreground">
                    <li>‚Ä¢ <strong>Manual Inspection:</strong> 12 human inspectors working 3 shifts</li>
                    <li>‚Ä¢ <strong>Detection Rate:</strong> Only 78% of defects caught before shipping</li>
                    <li>‚Ä¢ <strong>Inspection Speed:</strong> 15 seconds per part (production bottleneck)</li>
                    <li>‚Ä¢ <strong>False Positives:</strong> 23% of good parts rejected (costly waste)</li>
                    <li>‚Ä¢ <strong>Inconsistency:</strong> Quality varied by inspector fatigue and shift</li>
                    <li>‚Ä¢ <strong>Customer Returns:</strong> $1.2M annual cost from defective parts</li>
                  </ul>
                </div>

                <h2 className="text-2xl font-medium text-foreground mt-12 mb-6">System Architecture & Design</h2>
                <p className="mb-6">
                  I designed a multi-camera computer vision system that could inspect parts in real-time on the production line:
                </p>

                <div className="bg-background border border-border p-6 rounded-lg mb-8">
                  <h3 className="text-lg font-medium text-foreground mb-4">Hardware & Infrastructure Setup</h3>
                  <pre className="text-sm text-muted-foreground overflow-x-auto">
                    <code>{`# Production Line Integration Architecture
production_line_setup = {
    "cameras": {
        "top_view": "Basler acA2440-75um (5MP, 75fps)",
        "side_view": "Basler acA2440-75um (5MP, 75fps)", 
        "detail_view": "Basler acA4024-29um (12MP, 29fps)"
    },
    "lighting": {
        "led_panels": "High-frequency LED panels (2000Hz)",
        "lighting_angles": [45, 90, 135],  # degrees
        "polarization": "Cross-polarized for glare reduction"
    },
    "edge_computing": {
        "device": "NVIDIA Jetson AGX Orin",
        "gpu_memory": "64GB",
        "inference_speed": "<50ms per part",
        "simultaneous_streams": 3
    },
    "mechanical": {
        "conveyor_speed": "1.2 m/s",
        "inspection_window": "800ms",
        "part_positioning": "Pneumatic fixture system"
    }
}

# Network Architecture
class QualityControlPipeline:
    def __init__(self):
        self.camera_manager = MultiCameraManager()
        self.defect_detector = YOLOv8DefectDetector()
        self.classification_model = EfficientNetClassifier()
        self.edge_processor = EdgeInferenceEngine()
        
    def initialize_cameras(self):
        """Configure cameras for optimal defect detection"""
        camera_config = {
            'exposure_time': 1000,  # microseconds
            'gain': 2.0,
            'trigger_mode': 'hardware',
            'pixel_format': 'RGB8',
            'fps': 30
        }
        
        for camera_id in ['top', 'side', 'detail']:
            self.camera_manager.configure_camera(camera_id, camera_config)
            
    def capture_synchronized_images(self, part_id):
        """Capture images from all cameras simultaneously"""
        trigger_signal = self.generate_hardware_trigger()
        
        images = {
            'top': self.camera_manager.capture('top', trigger_signal),
            'side': self.camera_manager.capture('side', trigger_signal), 
            'detail': self.camera_manager.capture('detail', trigger_signal)
        }
        
        return images, part_id`}</code>
                  </pre>
                </div>

                <h2 className="text-2xl font-medium text-foreground mt-12 mb-6">Deep Learning Model Development</h2>
                <p className="mb-6">
                  I developed a multi-stage detection system combining object detection and classification:
                </p>

                <h3 className="text-xl font-medium text-foreground mt-8 mb-4">Stage 1: Defect Localization with YOLOv8</h3>
                <div className="bg-background border border-border p-6 rounded-lg mb-8">
                  <h4 className="font-medium text-foreground mb-4">Custom YOLOv8 Training Pipeline</h4>
                  <pre className="text-sm text-muted-foreground overflow-x-auto">
                    <code>{`import torch
from ultralytics import YOLO
import albumentations as A
from pathlib import Path

class DefectDetectionTrainer:
    def __init__(self):
        self.model = YOLO('yolov8n.pt')  # Start with pre-trained weights
        self.defect_classes = [
            'scratch', 'dent', 'crack', 'discoloration', 
            'burr', 'incomplete_hole', 'dimension_error'
        ]
        
    def setup_augmentations(self):
        """Aggressive augmentation for defect robustness"""
        return A.Compose([
            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),
            A.GaussNoise(var_limit=(10, 50), p=0.5),
            A.MotionBlur(blur_limit=7, p=0.3),
            A.RandomGamma(gamma_limit=(70, 130), p=0.4),
            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=20, p=0.6),
            A.RandomRotate90(p=0.5),
            A.Flip(p=0.5),
            A.Affine(scale=(0.8, 1.2), translate_percent=0.1, rotate=(-15, 15), p=0.7),
            # Manufacturing-specific augmentations
            A.OpticalDistortion(distort_limit=0.1, shift_limit=0.1, p=0.3),
            A.GridDistortion(num_steps=5, distort_limit=0.1, p=0.3),
        ])
    
    def train_defect_detector(self, dataset_path, epochs=200):
        """Train YOLOv8 for defect detection"""
        
        # Custom training configuration
        training_config = {
            'data': f'{dataset_path}/dataset.yaml',
            'epochs': epochs,
            'imgsz': 640,
            'batch': 16,
            'lr0': 0.01,
            'weight_decay': 0.0005,
            'mosaic': 0.5,  # Reduced for precision parts
            'mixup': 0.1,
            'copy_paste': 0.0,  # Disabled for manufacturing
            'degrees': 15,
            'translate': 0.1,
            'scale': 0.2,
            'perspective': 0.0001,
            'flipud': 0.5,
            'fliplr': 0.5,
            'hsv_h': 0.015,
            'hsv_s': 0.7,
            'hsv_v': 0.4
        }
        
        # Train the model
        results = self.model.train(**training_config)
        
        # Validate on test set
        test_results = self.model.val(data=f'{dataset_path}/dataset.yaml')
        
        return results, test_results
    
    def optimize_for_edge_deployment(self):
        """Convert model for edge inference"""
        
        # Export to TensorRT for NVIDIA Jetson
        self.model.export(
            format='engine',  # TensorRT format
            half=True,        # FP16 precision
            workspace=4,      # 4GB workspace
            verbose=True
        )
        
        # Benchmark performance
        inference_times = []
        for _ in range(100):
            start = time.time()
            results = self.model.predict('test_image.jpg')
            inference_times.append(time.time() - start)
            
        avg_inference_time = np.mean(inference_times)
        print(f"Average inference time: {avg_inference_time*1000:.2f}ms")
        
        return avg_inference_time`}</code>
                  </pre>
                </div>

                <h3 className="text-xl font-medium text-foreground mt-8 mb-4">Stage 2: Defect Classification & Severity Assessment</h3>
                <div className="bg-background border border-border p-6 rounded-lg mb-8">
                  <h4 className="font-medium text-foreground mb-4">Multi-Class Severity Classifier</h4>
                  <pre className="text-sm text-muted-foreground overflow-x-auto">
                    <code>{`import torch.nn as nn
import timm
from torch.utils.data import DataLoader

class DefectSeverityClassifier(nn.Module):
    def __init__(self, num_classes=21):  # 7 defects √ó 3 severity levels
        super().__init__()
        
        # Use EfficientNet as backbone
        self.backbone = timm.create_model('efficientnet_b3', pretrained=True)
        self.backbone.classifier = nn.Identity()
        
        # Custom head for defect classification
        self.classifier_head = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(1536, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.4),
            nn.Linear(512, 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Linear(128, num_classes)
        )
        
        # Separate severity assessment head
        self.severity_head = nn.Sequential(
            nn.Dropout(0.2),
            nn.Linear(1536, 256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Linear(256, 3)  # Minor, Major, Critical
        )
        
    def forward(self, x):
        features = self.backbone(x)
        defect_logits = self.classifier_head(features)
        severity_logits = self.severity_head(features)
        
        return defect_logits, severity_logits

class DefectClassificationPipeline:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = DefectSeverityClassifier().to(self.device)
        self.decision_thresholds = {
            'minor': 0.3,    # Allow minor defects
            'major': 0.15,   # Strict threshold for major defects
            'critical': 0.05 # Extremely strict for critical defects
        }
        
    def classify_defect_severity(self, defect_crop):
        """Classify defect type and assess severity"""
        
        # Preprocess defect crop
        processed_image = self.preprocess_defect(defect_crop)
        
        with torch.no_grad():
            defect_logits, severity_logits = self.model(processed_image)
            
            # Get predictions
            defect_probs = torch.softmax(defect_logits, dim=1)
            severity_probs = torch.softmax(severity_logits, dim=1)
            
            defect_class = torch.argmax(defect_probs, dim=1)
            severity_class = torch.argmax(severity_probs, dim=1)
            
        return {
            'defect_type': self.get_defect_name(defect_class),
            'defect_confidence': float(torch.max(defect_probs)),
            'severity_level': self.get_severity_name(severity_class),
            'severity_confidence': float(torch.max(severity_probs)),
            'reject_part': self.should_reject_part(severity_class, severity_probs)
        }
    
    def should_reject_part(self, severity_class, severity_probs):
        """Determine if part should be rejected based on severity"""
        severity_names = ['minor', 'major', 'critical']
        severity_name = severity_names[severity_class]
        confidence = float(torch.max(severity_probs))
        
        threshold = self.decision_thresholds[severity_name]
        
        # Reject if confidence exceeds threshold for this severity level
        return confidence > threshold`}</code>
                  </pre>
                </div>

                <h2 className="text-2xl font-medium text-foreground mt-12 mb-6">Real-Time Production Integration</h2>
                <p className="mb-6">
                  The system needed to integrate seamlessly with existing production workflows:
                </p>

                <div className="bg-background border border-border p-6 rounded-lg mb-8">
                  <h4 className="font-medium text-foreground mb-4">Production Line Integration System</h4>
                  <pre className="text-sm text-muted-foreground overflow-x-auto">
                    <code>{`import asyncio
import time
from collections import deque
import logging

class ProductionLineController:
    def __init__(self):
        self.inspection_queue = deque(maxlen=1000)
        self.results_queue = deque(maxlen=1000)
        self.conveyor_controller = ConveyorController()
        self.rejection_system = PneumaticRejector()
        self.plc_interface = PLCInterface()
        
    async def real_time_inspection_loop(self):
        """Main inspection loop running continuously"""
        
        while True:
            try:
                # Wait for part detection trigger
                part_detected = await self.wait_for_part_trigger()
                
                if part_detected:
                    part_id = self.generate_part_id()
                    
                    # Capture images from all cameras
                    images = await self.capture_multi_angle_images(part_id)
                    
                    # Run AI inspection (parallel processing)
                    inspection_task = asyncio.create_task(
                        self.run_ai_inspection(images, part_id)
                    )
                    
                    # Continue conveyor movement
                    self.conveyor_controller.continue_movement()
                    
                    # Get inspection results
                    inspection_result = await inspection_task
                    
                    # Make pass/fail decision
                    decision = self.make_quality_decision(inspection_result)
                    
                    # Execute rejection if needed
                    if decision['action'] == 'reject':
                        await self.trigger_rejection(part_id, decision)
                    
                    # Log results for traceability
                    self.log_inspection_result(part_id, inspection_result, decision)
                    
            except Exception as e:
                logging.error(f"Inspection error: {e}")
                await self.handle_inspection_error(e)
    
    async def run_ai_inspection(self, images, part_id):
        """Run complete AI inspection pipeline"""
        
        start_time = time.time()
        
        # Stage 1: Object detection for all views
        detection_tasks = []
        for view, image in images.items():
            task = asyncio.create_task(
                self.defect_detector.detect_defects(image, view)
            )
            detection_tasks.append(task)
        
        detection_results = await asyncio.gather(*detection_tasks)
        
        # Stage 2: Classify detected defects
        classification_results = []
        for detections in detection_results:
            for detection in detections:
                defect_crop = self.extract_defect_region(detection)
                classification = await self.classifier.classify_defect_severity(defect_crop)
                classification_results.append(classification)
        
        # Stage 3: Aggregate results
        final_result = self.aggregate_inspection_results(
            detection_results, 
            classification_results
        )
        
        inspection_time = time.time() - start_time
        final_result['processing_time_ms'] = inspection_time * 1000
        
        return final_result
    
    def make_quality_decision(self, inspection_result):
        """Make final pass/fail decision based on all defects"""
        
        decision = {
            'action': 'pass',
            'confidence': 1.0,
            'defects_found': [],
            'rejection_reason': None
        }
        
        # Check each detected defect
        for defect in inspection_result['defects']:
            severity = defect['severity_level']
            confidence = defect['severity_confidence']
            
            # Critical defects always reject
            if severity == 'critical' and confidence > 0.8:
                decision['action'] = 'reject'
                decision['rejection_reason'] = f"Critical {defect['defect_type']} detected"
                decision['confidence'] = confidence
                break
                
            # Major defects reject if high confidence
            elif severity == 'major' and confidence > 0.9:
                decision['action'] = 'reject'
                decision['rejection_reason'] = f"Major {defect['defect_type']} detected"
                decision['confidence'] = confidence
                break
                
            # Multiple minor defects can trigger rejection
            elif severity == 'minor':
                decision['defects_found'].append(defect)
        
        # Reject if too many minor defects
        if len(decision['defects_found']) >= 3:
            decision['action'] = 'reject'
            decision['rejection_reason'] = "Multiple minor defects detected"
            decision['confidence'] = 0.85
        
        return decision`}</code>
                  </pre>
                </div>

                <h2 className="text-2xl font-medium text-foreground mt-12 mb-6">Results & Performance Metrics</h2>
                <p className="mb-6">
                  After 3 months of operation, the AI quality control system delivered exceptional results:
                </p>

                <div className="grid md:grid-cols-2 gap-6 mb-8">
                  <div className="bg-secondary p-6">
                    <h4 className="font-medium text-foreground mb-4">Before AI Implementation</h4>
                    <ul className="space-y-2 text-sm text-muted-foreground">
                      <li>‚Ä¢ Defect Detection Rate: <strong className="text-red-400">78%</strong></li>
                      <li>‚Ä¢ False Positive Rate: <strong className="text-red-400">23%</strong></li>
                      <li>‚Ä¢ Inspection Speed: <strong>15 sec/part</strong></li>
                      <li>‚Ä¢ Customer Returns: <strong className="text-red-400">$1.2M/year</strong></li>
                      <li>‚Ä¢ Inspector Consistency: <strong className="text-red-400">Variable</strong></li>
                      <li>‚Ä¢ Production Throughput: <strong>240 parts/hour</strong></li>
                    </ul>
                  </div>
                  <div className="bg-secondary p-6">
                    <h4 className="font-medium text-foreground mb-4">After AI Implementation</h4>
                    <ul className="space-y-2 text-sm text-muted-foreground">
                      <li>‚Ä¢ Defect Detection Rate: <strong className="text-green-400">99.7%</strong> (+28%)</li>
                      <li>‚Ä¢ False Positive Rate: <strong className="text-green-400">2.1%</strong> (-91%)</li>
                      <li>‚Ä¢ Inspection Speed: <strong className="text-green-400">1.2 sec/part</strong> (-92%)</li>
                      <li>‚Ä¢ Customer Returns: <strong className="text-green-400">$0.4M/year</strong> (-67%)</li>
                      <li>‚Ä¢ Inspector Consistency: <strong className="text-green-400">100%</strong></li>
                      <li>‚Ä¢ Production Throughput: <strong className="text-green-400">3000 parts/hour</strong> (+1150%)</li>
                    </ul>
                  </div>
                </div>

                <h3 className="text-xl font-medium text-foreground mt-8 mb-4">Detailed Performance Analysis</h3>
                <div className="bg-background border border-border p-6 rounded-lg mb-8">
                  <h4 className="font-medium text-foreground mb-4">Per-Defect Detection Accuracy</h4>
                  <div className="grid grid-cols-2 gap-4 text-sm">
                    <div>
                      <ul className="space-y-1 text-muted-foreground">
                        <li>‚Ä¢ Scratches: <strong className="text-green-400">99.8%</strong></li>
                        <li>‚Ä¢ Dents: <strong className="text-green-400">99.6%</strong></li>
                        <li>‚Ä¢ Cracks: <strong className="text-green-400">99.9%</strong></li>
                        <li>‚Ä¢ Discoloration: <strong className="text-green-400">98.9%</strong></li>
                      </ul>
                    </div>
                    <div>
                      <ul className="space-y-1 text-muted-foreground">
                        <li>‚Ä¢ Burrs: <strong className="text-green-400">99.4%</strong></li>
                        <li>‚Ä¢ Incomplete Holes: <strong className="text-green-400">100%</strong></li>
                        <li>‚Ä¢ Dimension Errors: <strong className="text-green-400">99.2%</strong></li>
                        <li>‚Ä¢ Overall Average: <strong className="text-green-400">99.7%</strong></li>
                      </ul>
                    </div>
                  </div>
                </div>

                <h2 className="text-2xl font-medium text-foreground mt-12 mb-6">Implementation Challenges & Solutions</h2>
                
                <div className="space-y-6 mb-8">
                  <div className="bg-yellow-50 dark:bg-yellow-900/20 p-6 border border-yellow-200 dark:border-yellow-800">
                    <h4 className="font-medium text-yellow-800 dark:text-yellow-200 mb-3">Challenge: Limited Training Data</h4>
                    <p className="text-sm text-yellow-700 dark:text-yellow-300 mb-2">
                      <strong>Problem:</strong> Only 500 images of defective parts available initially.
                    </p>
                    <p className="text-sm text-yellow-700 dark:text-yellow-300">
                      <strong>Solution:</strong> Implemented synthetic defect generation using GANs and aggressive data augmentation. Generated 10,000+ synthetic defect images that were validated by quality engineers.
                    </p>
                  </div>
                  
                  <div className="bg-blue-50 dark:bg-blue-900/20 p-6 border border-blue-200 dark:border-blue-800">
                    <h4 className="font-medium text-blue-800 dark:text-blue-200 mb-3">Challenge: Edge Computing Constraints</h4>
                    <p className="text-sm text-blue-700 dark:text-blue-300 mb-2">
                      <strong>Problem:</strong> Real-time inference required on manufacturing floor with limited compute.
                    </p>
                    <p className="text-sm text-blue-700 dark:text-blue-300">
                      <strong>Solution:</strong> Model optimization through TensorRT, FP16 precision, and custom CUDA kernels. Achieved sub-50ms inference times while maintaining accuracy.
                    </p>
                  </div>
                  
                  <div className="bg-purple-50 dark:bg-purple-900/20 p-6 border border-purple-200 dark:border-purple-800">
                    <h4 className="font-medium text-purple-800 dark:text-purple-200 mb-3">Challenge: Production Line Integration</h4>
                    <p className="text-sm text-purple-700 dark:text-purple-300 mb-2">
                      <strong>Problem:</strong> Existing PLC systems needed to communicate with AI system seamlessly.
                    </p>
                    <p className="text-sm text-purple-700 dark:text-purple-300">
                      <strong>Solution:</strong> Developed custom Modbus TCP interface with fail-safe mechanisms. System defaults to manual inspection if AI system fails.
                    </p>
                  </div>
                </div>

                <h2 className="text-2xl font-medium text-foreground mt-12 mb-6">ROI & Business Impact</h2>
                <p className="mb-6">
                  The financial impact exceeded expectations within the first year:
                </p>

                <div className="grid md:grid-cols-3 gap-6 mb-8">
                  <div className="bg-secondary p-6 text-center">
                    <div className="text-2xl font-bold text-accent mb-2">$1.8M</div>
                    <div className="text-sm text-muted-foreground">Annual Savings</div>
                    <div className="text-xs text-muted-foreground mt-1">Reduced defects & waste</div>
                  </div>
                  <div className="bg-secondary p-6 text-center">
                    <div className="text-2xl font-bold text-accent mb-2">320%</div>
                    <div className="text-sm text-muted-foreground">ROI First Year</div>
                    <div className="text-xs text-muted-foreground mt-1">Implementation cost: $560K</div>
                  </div>
                  <div className="bg-secondary p-6 text-center">
                    <div className="text-2xl font-bold text-accent mb-2">1150%</div>
                    <div className="text-sm text-muted-foreground">Throughput Increase</div>
                    <div className="text-xs text-muted-foreground mt-1">240 ‚Üí 3000 parts/hour</div>
                  </div>
                </div>

                <h2 className="text-2xl font-medium text-foreground mt-12 mb-6">Future Enhancements</h2>
                <p className="mb-6">
                  The system continues to evolve with additional capabilities:
                </p>

                <ul className="list-disc list-inside mb-8 space-y-2 text-muted-foreground">
                  <li>3D vision integration for dimensional accuracy verification</li>
                  <li>Predictive maintenance alerts based on defect pattern analysis</li>
                  <li>Automated root cause analysis linking defects to process parameters</li>
                  <li>Digital twin integration for process optimization recommendations</li>
                  <li>Cross-facility deployment with federated learning capabilities</li>
                </ul>

                <div className="bg-accent/10 border border-accent/20 p-6 rounded-lg mb-8">
                  <h3 className="text-lg font-medium text-foreground mb-4">üí° Key Insight</h3>
                  <p className="text-muted-foreground">
                    The most critical success factor wasn't the AI model accuracy‚Äîit was seamless integration 
                    with existing manufacturing processes. The system needed to enhance, not disrupt, 
                    established workflows while providing immediate value to operators and quality engineers.
                  </p>
                </div>

                <div className="border-t border-border pt-8 mt-12">
                  <p className="text-muted-foreground">
                    Ready to implement computer vision quality control in your manufacturing process? 
                    <Link to="/contact" className="text-accent hover:text-foreground ml-1">
                      Let's discuss how AI can transform your production line ‚Üí
                    </Link>
                  </p>
                </div>
              </article>

              {/* Related Articles */}
              <div className="mt-16 pt-8 border-t border-border">
                <h3 className="text-xl font-medium text-foreground mb-6">Related Articles</h3>
                <div className="grid md:grid-cols-2 gap-6">
                  <Link to="/blog/churn-prediction-ml-solution" className="block p-6 border border-border hover:border-accent transition-colors">
                    <h4 className="font-medium text-foreground mb-2">How I Reduced Customer Churn by 34% Using ML</h4>
                    <p className="text-sm text-muted-foreground">ML-powered churn prediction system that saved $2.3M annually</p>
                  </Link>
                  <Link to="/blog/nlp-sentiment-analysis-ecommerce" className="block p-6 border border-border hover:border-accent transition-colors">
                    <h4 className="font-medium text-foreground mb-2">NLP-Powered Customer Sentiment Analysis</h4>
                    <p className="text-sm text-muted-foreground">Real-time sentiment analysis increasing conversion rates by 28%</p>
                  </Link>
                </div>
              </div>
            </div>
          </div>
        </div>
      </Layout>
    </>
  );
};

export default ComputerVisionQualityControl;